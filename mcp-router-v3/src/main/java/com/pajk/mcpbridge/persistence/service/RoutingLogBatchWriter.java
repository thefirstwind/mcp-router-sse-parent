package com.pajk.mcpbridge.persistence.service;

import com.pajk.mcpbridge.persistence.entity.RoutingLog;
import com.pajk.mcpbridge.persistence.mapper.RoutingLogMapper;
import jakarta.annotation.PostConstruct;
import jakarta.annotation.PreDestroy;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.stereotype.Service;
import reactor.core.Disposable;
import reactor.core.publisher.Flux;
import reactor.core.scheduler.Schedulers;

import java.time.Duration;
import java.util.List;
import java.util.concurrent.atomic.AtomicLong;

/**
 * è·¯ç”±æ—¥å¿—æ‰¹é‡å†™å…¥æœåŠ¡
 * 
 * è®¾è®¡åŸåˆ™:
 * 1. æ‰¹é‡å†™å…¥ - 2ç§’çª—å£æˆ–500æ¡è®°å½•è§¦å‘å†™å…¥
 * 2. å¼‚æ­¥å¤„ç† - ä½¿ç”¨ç‹¬ç«‹çº¿ç¨‹æ± ï¼Œä¸é˜»å¡ä¸»æµç¨‹
 * 3. æ•…éšœé™çº§ - æ•°æ®åº“å¤±è´¥æ—¶è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
 * 
 * @author MCP Router Team
 * @since 1.0.0
 */
@Slf4j
@Service
@RequiredArgsConstructor
@ConditionalOnProperty(
    prefix = "mcp.persistence",
    name = "enabled",
    havingValue = "true"
)
public class RoutingLogBatchWriter {
    
    private final RoutingLogMapper routingLogMapper;
    private final PersistenceEventPublisher eventPublisher;
    
    private Disposable subscription;
    
    // æ€§èƒ½ç»Ÿè®¡
    private final AtomicLong batchCount = new AtomicLong(0);
    private final AtomicLong recordCount = new AtomicLong(0);
    private final AtomicLong failureCount = new AtomicLong(0);
    
    // é…ç½®å‚æ•°
    private static final int BATCH_SIZE = 500;
    private static final Duration BATCH_WINDOW = Duration.ofSeconds(2);
    
    /**
     * å¯åŠ¨æ‰¹é‡å†™å…¥è®¢é˜…
     */
    @PostConstruct
    public void start() {
        log.info("Starting RoutingLog batch writer with batchSize={}, window={}", BATCH_SIZE, BATCH_WINDOW);
        log.info("Sampling strategy: Success=100%, Failure=100% (Full recording enabled)");
        
        try {
            subscription = eventPublisher.getRoutingLogSink()
                .asFlux()
                .doOnSubscribe(sub -> log.info("âœ… RoutingLog batch writer subscribed to event stream"))
                .doOnNext(routingLog -> log.trace("ğŸ“¥ Received routing log: {}", routingLog))
                .cast(RoutingLog.class)
                .filter(this::shouldSample) // åº”ç”¨é‡‡æ ·ç­–ç•¥
                .doOnNext(routingLog -> log.trace("âœ… Routing log passed sampling filter: {}", routingLog.getRequestId()))
                .bufferTimeout(BATCH_SIZE, BATCH_WINDOW)
                .filter(batch -> !batch.isEmpty())
                .doOnNext(batch -> log.debug("ğŸ“¦ Batching {} routing logs for write", batch.size()))
                .flatMap(this::writeBatch, 1) // å¹¶å‘åº¦ä¸º1ï¼Œä¿è¯é¡ºåº
                .subscribeOn(Schedulers.boundedElastic())
                .subscribe(
                    count -> log.debug("âœ… Batch write completed: {} records", count),
                    error -> {
                        log.error("âŒ Batch write error in RoutingLogBatchWriter", error);
                        failureCount.incrementAndGet();
                    },
                    () -> log.warn("âš ï¸ RoutingLog batch writer stream completed (unexpected)")
                );
            
            log.info("âœ… RoutingLog batch writer started successfully and subscribed to event stream");
        } catch (Exception e) {
            log.error("âŒ Failed to start RoutingLog batch writer", e);
            throw new RuntimeException("Failed to start RoutingLog batch writer", e);
        }
    }
    
    /**
     * é‡‡æ ·ç­–ç•¥ï¼šæˆåŠŸè¯·æ±‚100%ï¼Œå¤±è´¥è¯·æ±‚100%ï¼ˆä¸´æ—¶è°ƒæ•´ä¸ºå…¨é‡è®°å½•ï¼‰
     */
    private boolean shouldSample(RoutingLog log) {
        // å¤±è´¥è¯·æ±‚ï¼š100% è®°å½•
        if (log.getIsSuccess() == null || !log.getIsSuccess()) {
            return true;
        }
        
        // æˆåŠŸè¯·æ±‚ï¼š100% é‡‡æ ·ï¼ˆåŸæ¥æ˜¯10%ï¼‰
        return true; // Math.random() < 0.1;
    }
    
    /**
     * åœæ­¢æ‰¹é‡å†™å…¥è®¢é˜…
     */
    @PreDestroy
    public void stop() {
        if (subscription != null && !subscription.isDisposed()) {
            subscription.dispose();
            log.info("RoutingLog batch writer stopped. Stats: batches={}, records={}, failures={}",
                batchCount.get(), recordCount.get(), failureCount.get());
        }
    }
    
    /**
     * æ‰¹é‡å†™å…¥æ•°æ®åº“
     */
    private Flux<Integer> writeBatch(List<RoutingLog> logs) {
        return Flux.defer(() -> {
            try {
                long startTime = System.currentTimeMillis();
                
                // æ‰§è¡Œæ‰¹é‡æ’å…¥
                int count = routingLogMapper.batchInsert(logs);
                
                long duration = System.currentTimeMillis() - startTime;
                
                // æ›´æ–°ç»Ÿè®¡
                batchCount.incrementAndGet();
                recordCount.addAndGet(count);
                
                log.info("Batch insert successful: {} records in {}ms", count, duration);
                
                // æ€§èƒ½å‘Šè­¦
                if (duration > 1000) {
                    log.warn("Slow batch insert detected: {}ms for {} records", duration, count);
                }
                
                return Flux.just(count);
                
            } catch (Exception e) {
                failureCount.incrementAndGet();
                log.error("Batch insert failed for {} records", logs.size(), e);
                
                // è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼Œå¸®åŠ©å®šä½ TypeHandler é—®é¢˜
                if (e.getMessage() != null && (e.getMessage().contains("Data too long") ||
                        e.getMessage().contains("Data truncation") ||
                        e.getMessage().contains("column") && e.getMessage().contains("too large"))) {
                    log.error("âš ï¸ Database column size limit exceeded. This usually means the truncation TypeHandler did not run. " +
                            "Please check: 1) MyBatisConfig#setTypeHandlersPackage æ˜¯å¦ç”Ÿæ•ˆ, " +
                            "2) RoutingLogMapper.xml çš„ insert/batchInsert æ˜¯å¦æ˜¾å¼æŒ‡å®šäº† TypeHandler, " +
                            "3) éƒ¨ç½²åŒ…ä¸­æ˜¯å¦åŒ…å«æœ€æ–°çš„ TypeHandler ç±»ã€‚ " +
                            "Sample log entry sizes: requestHeaders={}, requestBody={}, responseHeaders={}, responseBody={}",
                            logs.stream().mapToInt(log -> log.getRequestHeaders() != null ? log.getRequestHeaders().getBytes().length : 0).max().orElse(0),
                            logs.stream().mapToInt(log -> log.getRequestBody() != null ? log.getRequestBody().getBytes().length : 0).max().orElse(0),
                            logs.stream().mapToInt(log -> log.getResponseHeaders() != null ? log.getResponseHeaders().getBytes().length : 0).max().orElse(0),
                            logs.stream().mapToInt(log -> log.getResponseBody() != null ? log.getResponseBody().getBytes().length : 0).max().orElse(0));
                }
                
                // é™çº§å¤„ç†ï¼šè®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
                fallbackToLog(logs);
                
                return Flux.empty();
            }
        });
    }
    
    /**
     * é™çº§å¤„ç†ï¼šå°†æ•°æ®è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
     */
    private void fallbackToLog(List<RoutingLog> logs) {
        log.warn("Fallback: Writing {} routing logs to file", logs.size());
        
        for (RoutingLog log : logs) {
            logToFile(log);
        }
    }
    
    /**
     * å°†å•æ¡è®°å½•å†™å…¥æ—¥å¿—æ–‡ä»¶
     */
    private void logToFile(RoutingLog routingLog) {
        // ä½¿ç”¨ç‰¹æ®Šçš„æ—¥å¿—æ ‡è®°ï¼Œä¾¿äºåç»­æ•°æ®æ¢å¤
        log.warn("PERSISTENCE_FALLBACK|ROUTING_LOG|requestId={}|method={}|serverKey={}|isSuccess={}|duration={}|createdAt={}",
            routingLog.getRequestId(),
            routingLog.getMethod(),
            routingLog.getServerKey(),
            routingLog.getIsSuccess(),
            routingLog.getDuration(),
            routingLog.getCreatedAt()
        );
    }
    
    /**
     * è·å–æ€§èƒ½ç»Ÿè®¡
     */
    public BatchWriterStats getStats() {
        return new BatchWriterStats(
            batchCount.get(),
            recordCount.get(),
            failureCount.get()
        );
    }
    
    /**
     * æ‰¹é‡å†™å…¥ç»Ÿè®¡
     */
    public record BatchWriterStats(
        long batchCount,
        long recordCount,
        long failureCount
    ) {
        public double avgBatchSize() {
            return batchCount == 0 ? 0 : (double) recordCount / batchCount;
        }
        
        public double failureRate() {
            return batchCount == 0 ? 0 : (double) failureCount / batchCount * 100;
        }
    }
}

